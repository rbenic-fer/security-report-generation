{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "aitextgen-hacker_news",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_"
      },
      "source": [
        "#  aitextgen — Train a GPT-2 (or GPT Neo) Text-Generating Model w/ GPU\n",
        "\n",
        "by [Max Woolf](https://minimaxir.com)\n",
        "\n",
        "*Last updated: May 16th, 2021 (aitextgen v0.5.2)*\n",
        "\n",
        "Retrain an advanced text generating neural network on any text dataset **for free on a GPU using Colaboratory** using `aitextgen`!\n",
        "\n",
        "For more about `aitextgen`, you can visit [this GitHub repository](https://github.com/minimaxir/aitextgen) or [read the documentation](https://docs.aitextgen.io/).\n",
        "\n",
        "\n",
        "To get started:\n",
        "\n",
        "1. Copy this notebook to your Google Drive to keep it and save your changes. (File -> Save a Copy in Drive)\n",
        "2. Run the cells below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_"
      },
      "source": [
        "!pip install -q aitextgen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3OamNzFToxk"
      },
      "source": [
        "import aitextgen\n",
        "import datetime\n",
        "import gc\n",
        "import logging\n",
        "import os\n",
        "import requests\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVYewreNaK6I"
      },
      "source": [
        "session_url = 'http://172.28.0.2:9000/api/sessions'\n",
        "notebook_name = requests.get(session_url).json()[0]['name']\n",
        "\n",
        "run_datetime = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
        "run_id = notebook_name + '_run_' + run_datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-ypL8bATo3z"
      },
      "source": [
        "log_format = '%(asctime)s — %(levelname)s — %(name)s — %(message)s'\n",
        "date_format = '%d/%m/%Y %H:%M:%S'\n",
        "log_level = logging.DEBUG\n",
        "\n",
        "logging.basicConfig(format=log_format, datefmt=date_format, level=log_level)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8KXuKWzQSsN"
      },
      "source": [
        "## Mounting Google Drive\n",
        "\n",
        "The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n",
        "\n",
        "Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq4iC6vUAHc"
      },
      "source": [
        "aitextgen.colab.mount_gdrive()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4_fMygRVH6K"
      },
      "source": [
        "gdrive_root_dir = '/content/drive/My Drive'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trRhgNvsH4Wn"
      },
      "source": [
        "## Loading GPT-2 or GPT Neo\n",
        "\n",
        "If you're retraining a model on new text, you need to download and load the GPT-2 model into the GPU. \n",
        "\n",
        "There are several sizes of GPT-2:\n",
        "\n",
        "* `124M` (default): the \"small\" model, 500MB on disk.\n",
        "* `355M` (default): the \"medium\" model, 1.5GB on disk.\n",
        "* `774M` (default): the \"large\" model, 3GB on disk.\n",
        "\n",
        "You can also finetune a GPT Neo model instead, which is more suitable for longer texts and the base model has more recent data:\n",
        "\n",
        "* `125M`: Analogous to the GPT-2 124M model.\n",
        "* `350M`: Analogous to the GPT-2 355M model\n",
        "\n",
        "The next cell downloads the model and saves it in the Colaboratory VM. If the model has already been downloaded, running this cell will reload it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flqSlHjMIeIw"
      },
      "source": [
        "ai = aitextgen.aitextgen(model='minimaxir/hacker-news', to_gpu=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text.\n",
        "\n",
        "**If you just trained a model**, you'll get much faster training performance if you reload the model; the next cell will reload the model you just trained from the `trained_model` folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cd0RGDbJiDp"
      },
      "source": [
        "`generate()` without any parameters generates a single text from the loaded model to the console."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R"
      },
      "source": [
        "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = ai.generate_one()`\n",
        "\n",
        "You can also pass in a `prompt` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
        "\n",
        "You can also generate multiple texts at a time by specifing `n`. You can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 50 for `batch_size` to avoid going OOM).\n",
        "\n",
        "Other optional-but-helpful parameters for `ai.generate()` and friends:\n",
        "\n",
        "*  **`min length`**: The minimum length of the generated text: if the text is shorter than this value after cleanup, aitextgen will generate another one.\n",
        "*  **`max_length`**: Number of tokens to generate (default 256, you can generate up to 1024 tokens with GPT-2 and 2048 with GPT Neo)\n",
        "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
        "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjjEN2Tafhl2"
      },
      "source": [
        "For bulk generation, you can generate a large amount of texts to a file and sort out the samples locally on your computer. The next cell will generate `num_files` files, each with `n` texts and whatever other parameters you would pass to `generate()`. The files can then be downloaded from the Files sidebar!\n",
        "\n",
        "You can rerun the cells as many times as you want for even more generated texts!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_outputs = 10\n",
        "max_length = 1000\n",
        "temperature = 1.0\n",
        "top_p = 0.9\n",
        "\n",
        "prompts = ['',\n",
        "           'APT41 is a ',\n",
        "           'APT41 is a state-sponsored espionage group ',\n",
        "           'Digital Forensics ',\n",
        "           'Digital Forensics Analysis Report',\n",
        "           'This report is ',\n",
        "           'The contents of ',\n",
        "           'Conclusion',\n",
        "           'It is recommended that ',\n",
        "           'In the opinion of the expert, ',\n",
        "           'File \\'Exploit_Office\\' contains ',\n",
        "           'File \\'Exploit_Office\\' does not contain ',\n",
        "           'Website \\'Webmail SquirrelMail\\' contains ',\n",
        "           'Website \\'Webmail SquirrelMail\\' does not contain ',\n",
        "           'New OneCoin Crypto Sale contains a link \\'http://',\n",
        "           'Note of eviction contains ',\n",
        "           'Note of eviction contains attachment ',\n",
        "           'Log entry found: ',\n",
        "           'Log entry found: Firewall (Type: Firewall) ',\n",
        "           'Log analysis on ']"
      ],
      "metadata": {
        "id": "CxZfHlURP6Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_root_dir = gdrive_root_dir + '/aitextgen/outputs/' + run_id\n",
        "output_ext = '.txt'\n",
        "\n",
        "if not os.path.exists(output_root_dir):\n",
        "    os.makedirs(output_root_dir)"
      ],
      "metadata": {
        "id": "QR-WDqL2Xldj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa6p6arifSL0"
      },
      "source": [
        "output_basepath = output_root_dir + '/' + run_id + '_output'\n",
        "\n",
        "for i in range(len(prompts)):\n",
        "    if len(prompts) > 1:\n",
        "        current_output = output_basepath + '.' + str(i) + output_ext\n",
        "    else:\n",
        "        current_output = output_basepath + output_ext\n",
        "    ai.generate_to_file(n=num_outputs,\n",
        "                        batch_size=1,\n",
        "                        prompt=prompts[i],\n",
        "                        max_length=max_length,\n",
        "                        temperature=temperature,\n",
        "                        top_p=top_p,\n",
        "                        destination_path=current_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmTXWNUygS5E"
      },
      "source": [
        "# LICENSE\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2020-2021 Max Woolf\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    }
  ]
}